{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_practice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstiaSun/deep-learning-practices/blob/master/practise7/cnn_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aMWYmHNJIybh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will create a simple CNN which will classify the images from mnist dataset. We will use neurol network API called [Keras](https://keras.io), which is one of the most popular libraries for neurol network processing in Python.\n",
        "You can run this notebook in [Google Colab](https://colab.research.google.com).\n",
        "\n",
        "Now let't import the Python library and load mnist dataset, which has been used in previous tutorials.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Y8VXR6UQGHHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac7da02f-4528-4dde-c274-89cea9d26faf"
      },
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ge6-NmxEG_eD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "61cc5b13-0c7e-4e81-a999-061d6980aa52"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nRPxW3I3IibB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's see what our loaded data consists of.\n",
        "We will show one of the images from dataset."
      ]
    },
    {
      "metadata": {
        "id": "5OIeCYRKHaKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "edc3bada-9e4c-42d8-b378-19e7ff0c3ea6"
      },
      "cell_type": "code",
      "source": [
        "# show one of the images from dataset\n",
        "import matplotlib.pyplot as ptl\n",
        "ptl.imshow(x_train[5])\n",
        "ptl.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1c00faecf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "r1ESbmuAKZuZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset consists of the images with extension 28x28.\n",
        "\n",
        "First of all, we will configure keras beckend and initialize the train and test tensors.\n",
        "Also we will normilize all elements in this tensor by dividing them on 255."
      ]
    },
    {
      "metadata": {
        "id": "kxgn-64OIu0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "# different channels may be used - this mode add the '1' to the end\n",
        "K.image_data_format()\n",
        "# reshape data\n",
        "N_train = x_train.shape[0]\n",
        "N_test = x_test.shape[0]\n",
        "rows = 28\n",
        "cols = 28\n",
        "x_train = x_train.reshape(N_train, rows, cols, 1) / 255\n",
        "x_test = x_test.reshape(N_test, rows, cols, 1) / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rXGc-78YH_AV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Secondly, we will create vectors of labels for training. We will use to_categorical function to create a binary matrix with these vectors. The first parameter is a vector of labels, the second is total amount of classes in vector."
      ]
    },
    {
      "metadata": {
        "id": "uOhJlgJ8J-MF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4NdEErDQJZwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we are ready to program a first model. It will be a simple 2-layer neural network we have worked previously. However now we need only 2 lines of code to create this layers. The schema of a network is below.\n",
        "\n",
        "![Fully conneted 2-layer network](https://github.com/AstiaSun/deep-learning-practices/blob/master/practise7/fully_connected_net_1.png)"
      ]
    },
    {
      "metadata": {
        "id": "wi0wjCjxKLW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPZeicoiKq23",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vKi6P4NrOocV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Flatten layer flatten the input. For instance, if inout tersor is 8x8x64, then the output will a vector with 4096 elements.\n",
        "\n",
        "Dense layer implements the activation operation. In example below the first arguments is a number of classes (respectively to amount of classes in the vector with labels). The second parameter is an activation function to use."
      ]
    },
    {
      "metadata": {
        "id": "iJ-vmwWlKyO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (raws, cols, 1)\n",
        "model.add(Flatten(input_shape=input_shape))\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIkopoSKP4Rs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After we have described the model, let's compile it. That's mean that the model will be configured. Optimizer, the first parameter, is an algorithm which will be used for finding the minimum. Metrics are the list of monitored metrix during the training."
      ]
    },
    {
      "metadata": {
        "id": "jCZtT3M1LPpX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zhNE-s7zRMvO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally by calling function fit the model will be trained. Here we specify the size of each batch, amount of epochs and train set.\n",
        "\n",
        "Next, the test set will we used to determine a value of error.  "
      ]
    },
    {
      "metadata": {
        "id": "kb7NL8j4MWnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "38378f49-f5ce-4ff9-d57c-cbe66b7250b4"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train_cat, batch_size=128, epochs=10)\n",
        "score = model.evaluate(x_test, y_test_cat)\n",
        "print(\"Accuracy =\", score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 2.2644 - acc: 0.4292\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 2.1900 - acc: 0.5875\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 2.1186 - acc: 0.6649\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.0499 - acc: 0.6837\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.9838 - acc: 0.7061\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 1.9201 - acc: 0.7270\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.8587 - acc: 0.7330\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.7998 - acc: 0.7457\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.7432 - acc: 0.7530\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 1.6890 - acc: 0.7585\n",
            "10000/10000 [==============================] - 1s 69us/step\n",
            "Accuracy = [1.6507347305297853, 0.7826]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5YCmH8t7UxKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see, the accuracy of neural network is about 78%. Now let's see how the accuracy will change if we will add a layer with [RELU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) as an acctivation function. \n",
        "\n",
        "The digram of a network:\n",
        "\n",
        "![Fully connected 3-layer network](https://github.com/AstiaSun/deep-learning-practices/blob/master/practise7/fully_connected_net_2.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "b5fAPVqoOivs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "cfe2d87b-a1b9-4dce-c0bd-7bcf43cf323f"
      },
      "cell_type": "code",
      "source": [
        "# now add new layer with RELU usage\n",
        "input_shape = (raws, cols, 1)\n",
        "model_relu = keras.models.Sequential()\n",
        "model_relu.add(Flatten(input_shape=input_shape))\n",
        "model_relu.add(Dense(100, activation=\"relu\"))\n",
        "model_relu.add(Dense(10, activation=\"softmax\"))\n",
        "model_relu.compile(optimizer=keras.optimizers.Adam(lr=0.0008), \n",
        "                   loss=keras.losses.categorical_crossentropy, \n",
        "                   metrics=['accuracy'])\n",
        "model_relu.fit(x_train, y_train_cat, batch_size=128, epochs=10)\n",
        "score = model_relu.evaluate(x_test, y_test_cat)\n",
        "print(\"Accuracy =\", score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 1.9545 - acc: 0.5466\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 1.1197 - acc: 0.7556\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.7531 - acc: 0.8237\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.5868 - acc: 0.8561\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.4962 - acc: 0.8733\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.4405 - acc: 0.8844\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.4036 - acc: 0.8914\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.3775 - acc: 0.8963\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.3585 - acc: 0.9004\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.3438 - acc: 0.9040\n",
            "10000/10000 [==============================] - 1s 73us/step\n",
            "Accuracy = [0.32810648040771484, 0.9097]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vZLc1LwVXsHH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see, the performance has increased to 90% with adding just one layer.\n",
        "But this is still not enough. Fully connected networks, which we have used previously, have a number of flaws:\n",
        "\n",
        "*   Spatial shape of an image is not taked into account\n",
        "*   Number of coeficients even in simple models is anormous\n",
        "*   We want to gain translation invariance (position change of object on the image do not impact the result) \n",
        "*   New data is not well generalized in fully connected networks\n",
        "\n",
        "The solution is to use [**convolutional neural networks (CNNs)**](https://en.wikipedia.org/wiki/Convolutional_neural_network). They cosists of a convolutional layer, an non-linear activation function, pooling layers, fully connected layers and softmax.\n",
        "\n",
        "\n",
        "At this momemt we will see how multilayer CNN wins in accuracy. The diagram shows the architecture of our network:\n",
        "\n",
        "![CNN schema which is going to be implemented](https://github.com/AstiaSun/deep-learning-practices/blob/master/practise7/cnn_practice_7.png)\n",
        "\n",
        "\n",
        "Two new types of layers has appeared. The first one (Conv2D) is a convolutional layer with RELU activation. The second one is a pooling layer (MaxPool2D)."
      ]
    },
    {
      "metadata": {
        "id": "RhN4fvMdShYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPool2D\n",
        "input_shape = (raws, cols, 1)\n",
        "model = keras.models.Sequential()\n",
        "# add convolutional kernel as the 1st layer with next parameters:\n",
        "# 32 - depth of a tenzor\n",
        "# kernel_zise - the size of a subset for which the filter will be used\n",
        "# padding - means that the output has the same length as the original input\n",
        "# input_shape - shape of an image\n",
        "# activation function - we are using RELU as activation function\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "# by default pool sixe is 2X2\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', \n",
        "                 input_shape=input_shape, activation='relu'))\n",
        "model.add(MaxPool2D(7, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0008), \n",
        "              loss=keras.losses.categorical_crossentropy, \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VnCddQtSVbkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "c94e5884-ac09-45b9-a66c-22b4c5aee592"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train_cat, batch_size=128, epochs=10)\n",
        "score = model.evaluate(x_test, y_test_cat)\n",
        "print(\"Accuracy =\", score)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.3155 - acc: 0.9139\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0764 - acc: 0.9766\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0541 - acc: 0.9827\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0431 - acc: 0.9867\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0342 - acc: 0.9897\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0288 - acc: 0.9910\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0253 - acc: 0.9916\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0227 - acc: 0.9929\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0168 - acc: 0.9949\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0163 - acc: 0.9948\n",
            "10000/10000 [==============================] - 1s 108us/step\n",
            "Accuracy = [0.043465278455188675, 0.9847]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Q912nJj8-VA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, you can see that we have gained the accuracy of approximately 98.5%.\n",
        "However, this is a great result, it is still not enough. In next practises we are going to see which architectures of CNN can improve a performance.\n",
        "\n",
        "To show the detailes of a trained model, you can call a function summary().\n",
        "It shows dimentions of each layer and amount of params it has received."
      ]
    },
    {
      "metadata": {
        "id": "phOhRGVtZjNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "6e7abcef-fa2b-4e8d-9da0-8ac0ca0ca1ef"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 93,962\n",
            "Trainable params: 93,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yIj00RzjZ7sO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "fbc5d526-cd56-4359-d270-741542505c9f"
      },
      "cell_type": "code",
      "source": [
        "# save results to google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/deep-learning-practices/\")\n",
        "\n",
        "# show model in json format\n",
        "json = model.to_json()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/deep-learning-practices/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-FdGuf2LJ88x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}