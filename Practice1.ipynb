{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classifier using least squares method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple classifier based on least square method.\n",
    "\n",
    "The data which we are using is written into two files - mnist_train.csv and mnist_test.csv. \n",
    "You can download it here: https://pjreddie.com/projects/mnist-in-csv/\n",
    "\n",
    "Attention! Reading data from csv files requires a lot of memory (up to couple of gigabytes) and computation power, run the following block of code only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images_and_labels_from_dataset(data, shape):\n",
    "    \"\"\"selects rundom images from dataset\"\"\"\n",
    "    old_shape = data.shape[0]\n",
    "    indexces = np.random.choice(old_shape, shape, replace=False)\n",
    "    labels = data[indexces, 0].astype(int)\n",
    "    images = data[indexces, 1:]\n",
    "    return labels, images\n",
    "\n",
    "def load_train_data():\n",
    "    \"\"\"reads csv file with train dataset\"\"\"\n",
    "    return np.genfromtxt(\"mnist_train.csv\", delimiter=',')\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"reads csv file with test dataset\"\"\"\n",
    "    return np.genfromtxt(\"mnist_test.csv\", delimiter=',')\n",
    "\n",
    "def load_data_and_select_train_images():\n",
    "    \"\"\"reads train data and selects rundom images from it\"\"\"\n",
    "    train_data = load_train_data()\n",
    "    print(train_data.shape)\n",
    "    return select_images_and_labels_from_dataset(train_data, N_train)\n",
    "\n",
    "def load_data_and_select_test_images():\n",
    "    \"\"\"reads test data and select rundom images from it\"\"\"\n",
    "    test_data = load_test_data()\n",
    "    print(test_data.shape)\n",
    "    return select_images_and_labels_from_dataset(test_data, N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the amount of images we will use to train the classifier and test it.\n",
    "After that we will load train and test data and select rundom images from those datasets.\n",
    "\n",
    "As you will see, there are 60k and 10k vectors in train and test data respectively. Each vector contains 785 values and represents an image 28X28 with a lable. First value in a vector is lables of an image - digit from 0 to 9, next 784 values are image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "N_train = 10000\n",
    "N_test = 1000\n",
    "train_labels, train_images = load_data_and_select_train_images()\n",
    "test_labels, test_images = load_data_and_select_test_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorythm of classfifier is the following:\n",
    "1. Select test image from test images\n",
    "2. Find the distances from selected image to train images\n",
    "3. Find minimum distance and return it's label from train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(test_image):\n",
    "    DM = np.square(test_image - train_images).sum(axis=1)\n",
    "    index = DM.argmin(axis=0)\n",
    "    return train_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results = [classify_image(test_image) for test_image in test_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the accuracy of our algorythm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLES COUNT: 10000\n",
      "TEST COUNT: 1000\n",
      "ACCURACY: 95.2 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = (predicted_results == test_labels).sum() / N_test\n",
    "print(\"SAMPLES COUNT:\", N_train)\n",
    "print(\"TEST COUNT:\", N_test)\n",
    "print(\"ACCURACY:\", np.round(accuracy * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, how we can maximise the accuracy? We will see how the size of train data influences the accuracy of image prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_average_accuracy(N_train, amount_of_iterations):\n",
    "    total_accuracy = 0\n",
    "    for i in range(amount_of_iterations):\n",
    "        train_labels, train_images = select_images_and_labels_from_dataset(train_data, N_train)\n",
    "        predicted_results = [classify_image(test_image) for test_image in test_images]\n",
    "        accuracy = (predicted_results == test_labels).sum() / N_test\n",
    "        total_accuracy += accuracy\n",
    "    return total_accuracy / amount_of_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 785)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cc7c8f31b7a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_and_select_test_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m accuracy_info = [get_average_accuracy(size, iters)\n\u001b[0;32m----> 7\u001b[0;31m                     for size, iters in zip(size_of_subset_v, count_of_iters_v)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-cc7c8f31b7a3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_and_select_test_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m accuracy_info = [get_average_accuracy(size, iters)\n\u001b[0;32m----> 7\u001b[0;31m                     for size, iters in zip(size_of_subset_v, count_of_iters_v)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-206a9176ce19>\u001b[0m in \u001b[0;36mget_average_accuracy\u001b[0;34m(N_train, amount_of_iterations)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamount_of_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_images_and_labels_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredicted_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassify_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_results\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtotal_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-206a9176ce19>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamount_of_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_images_and_labels_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredicted_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassify_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_results\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtotal_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-db7ed6c25a4d>\u001b[0m in \u001b[0;36mclassify_image\u001b[0;34m(test_image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mDM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size_of_subset_v = [50,  200, 500, 1000, 2000, 5000, 10000]\n",
    "count_of_iters_v = [100, 40,  20,  15,   10,   3,    1]\n",
    "\n",
    "train_data = load_train_data()\n",
    "test_labels, test_images = load_data_and_select_test_images()\n",
    "accuracy_info = [get_average_accuracy(size, iters)\n",
    "                    for size, iters in zip(size_of_subset_v, count_of_iters_v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize results with mathplotlib. Note that x-axis is logarithmically scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.semilogx(size_of_subset_v, accuracy_info, color = \"g\")\n",
    "plt.scatter(size_of_subset_v, accuracy_info, color = \"b\")\n",
    "\n",
    "plt.xlabel(\"Size of train subset\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(axis=\"y\", which=\"both\", linestyle='--')\n",
    "plt.grid(axis=\"x\", which=\"both\", linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
